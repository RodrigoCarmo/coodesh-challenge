# Fitness Foods LC - API

## Introdu√ß√£o

Est√° API faz parte do desafio proposto pela [Teddy Open Finance](https://teddydigital.io/). Ir√° importar produtos da API p√∫blica [Open Food Facts](https://world.openfoodfacts.org/) atrav√©s de rotinas administradas com o Cron e armazen√°-las no banco de dados da Fitness Foods LC.

[Link da apresenta√ß√£o](https://www.loom.com/embed/1f7822ad4aa8480eb245acb1338dd36e)

### Etapas do desenvolvimento

**1¬∫ dia:**
- Nesta primeira etapa, irei ler o README do desafio e preparar o ambiente para o desenvolvimento. Irei utilizar o [Nestjs](https://nestjs.com/) para a cria√ß√£o da api, para a base de dados, irei utilizar o [PostgreSQL](https://www.postgresql.org/), embora a √™nfase do desafio seja o [MongoDB](https://www.mongodb.com/), eu irei utilizar o que estou mais ambientado, assim, posso produzir em maior tempo (mesmo sabendo que para este cen√°rio um noSql poderia ser mais perform√°tico em alguns casos) e n√£o perderei um tempo maior para a entrega do projeto.
- Gerei a estrutura base do projeto conforme mencionado.
- Dei inicio ao job com a leitura e parse dos dados necess√°rios e preparei os reposit√≥rios para o typeorm. Para amanh√£, irei implementar a l√≥gica de controle do processamento na nossa base de dados para assim adentrar em maioires detalhes.

**2¬∫ dia:**
- Fiz a implementa√ß√£o 100% funcional do parse e formata√ß√£o dos dados para import√°-los no banco de dados
- Realizei umas adapta√ß√µes no funcionamento do Cron Job, isto porqu√™ h√° arquivos muito grandes para busca e inser√ß√£o. A princ√≠pio, o endpoint que utilizamos para buscar os arquivos possui uma limita√ß√£o para stream dos dados. Essa limita√ß√£o gera um 403 e demora um pouco a funcionar novamente. Assim, implementei uma esp√©cie de estado para o job, armazenando um contador para o controle de quantos arquivos ser√£o solicitados por dia afim de manter os 100 produtos propostos no desafio. Tamb√©m realizei um controle pela data ap√≥s exceder o limite de arquivos lidos no dia, assim, mesmo que o cron rode em segundo plano, ele n√£o ir√° realizar nenhuma tarefa e manter√° os 100 produtos por arquivo ao dia. Obs: o Cron ir√° disparar a cada uma hora por dia, por√©m, ir√° realizar apenas as importa√ß√µes necess√°rias no per√≠odo.
- Adicionei uma tabela para controlar em qual linha(estado) se encontra o arquivo para o processamento. Vale ressaltar que a busca do arquivo √© armazenada em disco, porqu√™ √© imprevis√≠vel saber uma determinada linha de um buffer e assim ficaria dif√≠cil de manipular os chunks sem gerar alguma m√° formata√ß√£o. E o nosso arquivo √© muito grande para manipul√°-lo em mem√≥ria, o que acaba derrubando a aplica√ß√£o.
- Implementei uma tabela que ir√° armazenar a performance da execu√ß√£o dos meus jobs.
- Estou implementando a rota de health check para exibir o estado do banco de dados e o √∫ltimo registro de performance do job. Amanh√£ irei finalizar esta etapa e fazer os ajustes finais para a entrega do desafio.

**3¬∫ dia:**
- Implementei as rotas de GET, PUT e DELETE
- Adicionei alguns logs para a execu√ß√£o do job
- Implementei o health check com o ping para o banco de dados e a busca das √∫ltimas informa√ß√µes de performance do job
- Fiz um teste na api de modo pr√°tico e est√° tudo ok
- Realizei algumas refatora√ß√µes
- Adicionei um rate limiter para os endpoints de produtos e health check
- Adicionei um middleware que redireciona as conexoes para do host para a documenta√ß√£o do swagger
- Adicionei o middleware para validar uma x-api-key nas requisi√ß√µes
- Corrigi o problema que causava 403 e n√£o tinha a ver com o servidor barrando minhas conex√µes, era apenas implementa√ß√£o incorreta de minha parte
- Corrigi o c√°lculo para o processamento m√©dio do uso da CPU
- Adicionei testes de integra√ß√£o para as rotas GET, PUT e DELETE dos products. Optei por integra√ß√£o ao inv√©s de unit√°rio porqu√™ acredito que n√£o havia muito o que testar nos meus services, sendo assim, os testes de integra√ß√£o j√° cobrem o necess√°rio para o momento. N√£o implementei testes para o job pois levaria maior complexidade de tempo, mas realizei v√°rios testes pr√°ticos para garantir o funcionamento adequado
- Realizei alguns ajustes finais para apresenta√ß√£o, o projeto est√° finalizado

## Tecnologias utilizadas

- [Nestjs](https://nestjs.com/)
- [Docker](https://www.docker.com/)
- [TypeORM](https://typeorm.io/)
- [PostgreSQL](https://www.postgresql.org/)
- [Jest](https://jestjs.io/)
- [Swagger](https://swagger.io/)
- [Beekeeper Studio](https://www.beekeeperstudio.io/)
- [Postman](https://www.postman.com/)

## Instru√ß√µes

Primeiramente fa√ßa a clonagem deste reposit√≥rio, voc√™ pode clon√°-lo via ssh ou https que ser√° o exemplo abordado aqui. Abaixo o comando para o clone:

```shell
git clone https://github.com/RodrigoCarmo/teddy-open-finance-challenge.git
```


**Observa√ß√£o**: Antes de mais nada, √© preciso se atentar ao .env, ele √© crucial para o funcionamento do projeto e principalmente do job schedule. As vari√°veis `JOB_STATE` e `DATE_TO_PAUSE_JOB` devem ser mantidas em branco, elas ser√£o preenchidas em tempo de execu√ß√£o e manipuladas da forma necess√°ria para a execu√ß√£o do job.


Para este projeto, n√≥s utilizaremos o [Docker](https://www.docker.com/) para provisionarmos nossos containers e n√£o nos preocuparmos com toda aquela configura√ß√£o massante que pode ocasionar falhas entre os executantes do projeto. O nosso projeto ser√° orquestrado pelo `Docker Compose`. O nosso projeto j√° executa a instala√ß√£o do `node_modules` ao executar o `Docker Compose.`

```shell
docker-compose up
```

Caso queira eliminar os containers executados:

```shell
docker-compose down
```

Outro detalhe importante a ressaltar √© que nossas migrations est√£o rodando sempre que iniciamos a aplica√ß√£o e isso √© recomendado apenas em ambiente de desenvolvimento.


Se voc√™ configurou corretamente as vari√°veis para o .env como no exemplo abaixo, o projeto est√° pronto para ser usado:

```
## NESTJS SERVER
HOST=localhost
PORT=3001
API_KEY=3VsOzHXdZENU5Tbjl9W6DpHg8BCgZVb0

## CRON STATE NODEJS, DEIXAR AS VARIAVEIS VAZIAS
JOB_STATE=
DATE_TO_PAUSE_JOB=

## DATABASE POSTGRES
PORT_PG=5432
HOST_PG=teddy_open_db
USERNAME_PG=teddy
PASSWORD_PG=12345678
DATABASE_PG=teddy_open_db

## OPEN FOOD FACTS
AVAILABLE_FILENAMES_URL=https://challenges.coode.sh/food/data/json/index.txt
FILENAME_URL=https://challenges.coode.sh/food/data/json/
```

Para acessar a nossa documenta√ß√£o de endpoints, voc√™ pode abrir atrav√©s do navegador na seguinte rota `https://localhost:<PORTA>` e voc√™ ser√° redirecionado para ela. L√° voc√™ obter√° as rotas que poder√° requisitar.

## Funcionamento do Job

Realizei algumas mudan√ßas para o uso do cron nativo do [Nestjs](https://nestjs.com/), em resumo, nosso job ser√° executado a cada 1 hora, mas calma, ele n√£o vai fazer nenhuma requisi√ß√£o ou nada complexo que demande processamento demasiado. O job apenas usar√° aquelas vari√°veis que deixamos em branco no in√≠cio para checar se um arquivo X j√° foi processado e tamb√©m se todos os arquivos dispon√≠veis j√° foram processados no dia. Temos o limite proposto pelo desafio de 100 importa√ß√µes por dia, assim, importamos 100 registros de cada arquivo dispon√≠vel e paramos nosso processamento at√© o dia seguinte.


Como os arquivos buscados s√£o enormes, tive alguns problemas no processamento do Buffer, isto porqu√™ √© imprevis√≠vel saber quantas linhas o Buffer possui e poder determinar os trechos que precisamos do [JSONL](https://jsonlines.org/) para processar por parte. E tamb√©m h√° o fato de qu√™ ao processar com uma stream os nossos chunks podem quebrar em partes erradas do nossos [JSONL](https://jsonlines.org/) e isso gerar uma formata√ß√£o inv√°lida no final, logo, optei por salvar o nosso arquivo primeiramente em disco, process√°-lo, fazer o salvamento na nossa base de dados e exclu√≠-lo.


Para controlar o processamento eu inclu√≠ duas tabelas, uma para gerenciar os arquivos e outra para podermos obter dados referentes ao processo dos mesmos. Na tabela de `files_manager` n√≥s armazenamos o estado do nosso arquivo e algumas outras informa√ß√µes, ou seja, em qual linha n√≥s paramos para a pr√≥xima rotina do job. Na `jobs_performance` n√≥s armazenamos registros de performance da execu√ß√£o e o status da execu√ß√£o, se foi sucedida ou obteve erro. Caso ocorra um erro, o arquivo ser√° processado na pr√≥xima rotina.

## Testes de integra√ß√£o

Basta executar: 

```shell
npm run test
```

ou

```shell
yarn test
```

Se voc√™ n√£o tiver o [npm](https://www.npmjs.com/) ou [yarn](https://yarnpkg.com/) e n√£o quiser instalar localmente, basta entrar no nosso container da seguinte maneira:

```shell
docker container exec -it teddy_open_api bash
```

Pronto, agora voc√™ poder√° rodar l√° dentro.

## Conclus√£o

√â isso, o meu caminho neste desafio chegou ao fim, agora vamos esperar o retorno da Teddy üôÇ



This is a challenge by [Coodesh](https://coodesh.com/)




